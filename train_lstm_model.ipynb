{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Window', 'Participant', 'Path', 'Run',\n",
       "       'median_Acceleration x (m/s^2)_head_mean',\n",
       "       'median_Acceleration x (m/s^2)_head_std',\n",
       "       'median_Acceleration x (m/s^2)_head_last',\n",
       "       'median_Acceleration x (m/s^2)_head_get_freq',\n",
       "       'median_Acceleration x (m/s^2)_head_get_weighted_freq',\n",
       "       'median_Acceleration x (m/s^2)_head_get_power_spectral_entropy',\n",
       "       ...\n",
       "       'median_Z (rad/s)_leg_last', 'median_Z (rad/s)_leg_get_freq',\n",
       "       'median_Z (rad/s)_leg_get_weighted_freq',\n",
       "       'median_Z (rad/s)_leg_get_power_spectral_entropy',\n",
       "       'median_Z (µT)_leg_mean', 'median_Z (µT)_leg_std',\n",
       "       'median_Z (µT)_leg_last', 'median_Z (µT)_leg_get_freq',\n",
       "       'median_Z (µT)_leg_get_weighted_freq',\n",
       "       'median_Z (µT)_leg_get_power_spectral_entropy'],\n",
       "      dtype='object', length=226)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.abspath('')\n",
    "path = path + \"/engineered_data_250ms_window80_step8.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "diction = {'Dany':0, 'Felix':1, 'Julian':2, 'Mark':3,'Martin':4,'Michele':5,'Paul':6}\n",
    "\n",
    "for index,row in df['Participant'].items():\n",
    "    df.loc[index,'Participant'] = diction[row]\n",
    "\n",
    "List = [\"Window\", \"Participant\", \"Run\", \"Path\"]\n",
    "for name in df.columns:\n",
    "    if \"Acceleration\" in name and not \"Linear\" in name:\n",
    "        List.append(name)\n",
    "\n",
    "# df.drop(df.columns.difference(List),axis=1,inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1019, 225), dtype=float32, numpy=\n",
       "array([[1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,           nan,\n",
       "                  nan,           nan],\n",
       "       [2.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,           nan,\n",
       "                  nan,           nan],\n",
       "       [3.0000000e+00, 1.0000000e+00, 1.0000000e+00, ...,           nan,\n",
       "                  nan,           nan],\n",
       "       ...,\n",
       "       [3.0000000e+01, 0.0000000e+00, 3.0000000e+00, ..., 2.5000000e-02,\n",
       "        1.2790108e-01, 3.4416955e+00],\n",
       "       [3.1000000e+01, 0.0000000e+00, 3.0000000e+00, ..., 0.0000000e+00,\n",
       "                  nan,           nan],\n",
       "       [3.2000000e+01, 0.0000000e+00, 3.0000000e+00, ..., 0.0000000e+00,\n",
       "                  nan,           nan]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST/TRAIN SPLIT GOES HERE\n",
    "X_Train = df[df['Run'] < 4].copy()\n",
    "X_Train\n",
    "X_Test = df[df['Run'] == 4].copy()\n",
    "\n",
    "Y_Train = X_Train['Participant'].copy().to_numpy()\n",
    "\n",
    "Y_Test = X_Test['Participant'].copy().to_numpy()\n",
    "\n",
    "\n",
    "X_Test.drop(['Participant'],axis=1,inplace=True)\n",
    "X_Train.drop(['Participant'],axis=1,inplace=True)\n",
    "X_Train.loc[X_Train['Path'] == 'circle', \"Path\"] = 1\n",
    "X_Train\n",
    "X_Train.loc[X_Train['Path'] == 'straight', \"Path\"] = 0\n",
    "X_Test.loc[X_Test['Path'] == 'circle',\"Path\"] = 1\n",
    "X_Train\n",
    "X_Test.loc[X_Test['Path'] == 'straight',\"Path\"] = 0\n",
    "X_Train\n",
    "X_Train = X_Train.to_numpy()\n",
    "X_Test = X_Test.to_numpy()\n",
    "X_Train.shape\n",
    "X_Train = np.asarray(X_Train).astype(np.float32)\n",
    "X_Test = np.asarray(X_Test).astype(np.float32)\n",
    "tf.convert_to_tensor(X_Test,dtype=tf.float32)\n",
    "tf.convert_to_tensor(X_Train,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.0000000e+00, 1.0000000e+00, 4.0000000e+00, ...,\n",
       "                   nan,           nan,           nan]],\n",
       "\n",
       "       [[2.0000000e+00, 1.0000000e+00, 4.0000000e+00, ...,\n",
       "                   nan,           nan,           nan]],\n",
       "\n",
       "       [[3.0000000e+00, 1.0000000e+00, 4.0000000e+00, ...,\n",
       "                   nan,           nan,           nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.2000000e+01, 1.0000000e+00, 4.0000000e+00, ...,\n",
       "         1.2500000e-02, 9.9776268e-02, 2.6692116e+00]],\n",
       "\n",
       "       [[2.3000000e+01, 1.0000000e+00, 4.0000000e+00, ...,\n",
       "         0.0000000e+00,           nan,           nan]],\n",
       "\n",
       "       [[2.4000000e+01, 1.0000000e+00, 4.0000000e+00, ...,\n",
       "         0.0000000e+00,           nan,           nan]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape it\n",
    "X_Train.reshape((X_Train.shape[0],1,X_Train.shape[1]))\n",
    "X_Test.reshape((X_Test.shape[0],1,X_Test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/Master/Quant/ML4QS-bike-user-recognition/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_Train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_Train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/Quant/ML4QS-bike-user-recognition/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Master/Quant/ML4QS-bike-user-recognition/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "look_back = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_Train, Y_Train, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "input_size = 10\n",
    "sequence_length = 10\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "num_classes = 7\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes, sequence_length=sequence_length):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        self.hidden_size  = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out,_ = self.gru(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0327, -0.0634, -0.0058, -0.0321,  0.0628,  0.0862, -0.0098],\n",
       "        [ 0.0188, -0.0644, -0.0378, -0.0357,  0.0343,  0.0577, -0.0523],\n",
       "        [-0.0082, -0.0535, -0.0086, -0.0477,  0.0366,  0.0763, -0.0186],\n",
       "        [-0.0045, -0.0285, -0.0314, -0.0491,  0.0479,  0.0511, -0.0032],\n",
       "        [ 0.0300, -0.0262, -0.0380, -0.0406,  0.0396,  0.0581, -0.0122],\n",
       "        [ 0.0510, -0.0452,  0.0055, -0.0245,  0.0568,  0.0450,  0.0015],\n",
       "        [-0.0060, -0.0222, -0.0123, -0.0575,  0.0463,  0.0492, -0.0050],\n",
       "        [ 0.0147, -0.0336, -0.0063, -0.0307,  0.0569,  0.0744, -0.0127],\n",
       "        [-0.0215, -0.0475, -0.0221, -0.0310,  0.0614,  0.0626,  0.0038],\n",
       "        [-0.0044, -0.0577, -0.0176, -0.0518,  0.0464,  0.0592, -0.0063],\n",
       "        [ 0.0275, -0.0314, -0.0138, -0.0314,  0.0509,  0.0673, -0.0082],\n",
       "        [ 0.0095, -0.0597, -0.0320, -0.0178,  0.0368,  0.0849,  0.0074],\n",
       "        [-0.0119, -0.0347, -0.0374, -0.0381,  0.0228,  0.0377,  0.0117],\n",
       "        [ 0.0098, -0.0313,  0.0037, -0.0029,  0.0288,  0.0900, -0.0014],\n",
       "        [ 0.0082, -0.0095, -0.0091, -0.0503,  0.0199,  0.0571,  0.0164],\n",
       "        [ 0.0068, -0.0569, -0.0368, -0.0444,  0.0345,  0.0743, -0.0213],\n",
       "        [ 0.0236, -0.0689, -0.0107, -0.0250,  0.0384,  0.0534, -0.0031],\n",
       "        [ 0.0314, -0.0323,  0.0005, -0.0257,  0.0484,  0.0522, -0.0043],\n",
       "        [ 0.0307, -0.0222, -0.0423, -0.0354,  0.0359,  0.0322, -0.0201],\n",
       "        [ 0.0241, -0.0362, -0.0433, -0.0357,  0.0382,  0.0687, -0.0124],\n",
       "        [ 0.0308, -0.0518, -0.0171, -0.0241,  0.0498,  0.0677,  0.0088],\n",
       "        [ 0.0016, -0.0511, -0.0212, -0.0409,  0.0450,  0.0665, -0.0228],\n",
       "        [ 0.0210, -0.0386, -0.0160, -0.0235,  0.0286,  0.0615, -0.0120],\n",
       "        [ 0.0211, -0.0380, -0.0231, -0.0690,  0.0182,  0.0434, -0.0157],\n",
       "        [-0.0022, -0.0547, -0.0017, -0.0385,  0.0230,  0.0530, -0.0010],\n",
       "        [-0.0068, -0.0308, -0.0265, -0.0692,  0.0583,  0.0608, -0.0100],\n",
       "        [ 0.0377, -0.0051, -0.0186, -0.0518,  0.0389,  0.0485, -0.0052],\n",
       "        [ 0.0178, -0.0484, -0.0271, -0.0598,  0.0474,  0.0482, -0.0150],\n",
       "        [-0.0123, -0.0524, -0.0231, -0.0456,  0.0342,  0.0509, -0.0142],\n",
       "        [ 0.0356, -0.0270, -0.0313, -0.0230,  0.0362,  0.0492, -0.0148],\n",
       "        [-0.0155, -0.0489, -0.0201, -0.0417,  0.0471,  0.0526, -0.0137],\n",
       "        [ 0.0041, -0.0439, -0.0194, -0.0368,  0.0379,  0.0590, -0.0279],\n",
       "        [ 0.0133, -0.0290, -0.0291, -0.0510,  0.0496,  0.0525,  0.0063],\n",
       "        [ 0.0409, -0.0531, -0.0391, -0.0486,  0.0315,  0.0726, -0.0329],\n",
       "        [ 0.0354, -0.0592, -0.0252, -0.0213,  0.0440,  0.0611, -0.0062],\n",
       "        [ 0.0059, -0.0354, -0.0184, -0.0785,  0.0520,  0.0296, -0.0272],\n",
       "        [ 0.0049, -0.0169, -0.0129, -0.0671,  0.0258,  0.0557,  0.0090],\n",
       "        [ 0.0083, -0.0771, -0.0084, -0.0573,  0.0488,  0.0879, -0.0195],\n",
       "        [ 0.0010, -0.0435, -0.0327, -0.0535,  0.0621,  0.0767, -0.0309],\n",
       "        [ 0.0261, -0.0473, -0.0241, -0.0406,  0.0404,  0.0760, -0.0075],\n",
       "        [-0.0036, -0.0386, -0.0219, -0.0452,  0.0367,  0.0583, -0.0179],\n",
       "        [ 0.0058, -0.0348, -0.0103, -0.0475,  0.0572,  0.0497,  0.0112],\n",
       "        [ 0.0250, -0.0553, -0.0260, -0.0660,  0.0602,  0.0296,  0.0019],\n",
       "        [ 0.0064, -0.0183,  0.0032, -0.0509,  0.0375,  0.0515,  0.0095],\n",
       "        [-0.0181, -0.0432, -0.0401, -0.0636,  0.0510,  0.0474, -0.0522],\n",
       "        [ 0.0522, -0.0477, -0.0330, -0.0225,  0.0564,  0.0743, -0.0155],\n",
       "        [ 0.0578, -0.0401, -0.0329, -0.0525,  0.0631,  0.0481, -0.0248],\n",
       "        [ 0.0257, -0.0274, -0.0177, -0.0212,  0.0514,  0.0802,  0.0207],\n",
       "        [ 0.0213, -0.0303, -0.0149, -0.0397,  0.0335,  0.0718, -0.0044],\n",
       "        [-0.0047, -0.0518, -0.0097, -0.0190,  0.0416,  0.0758, -0.0142],\n",
       "        [-0.0018, -0.0340, -0.0142, -0.0654,  0.0419,  0.0542,  0.0072],\n",
       "        [ 0.0517, -0.0543, -0.0430, -0.0416,  0.0610,  0.0632, -0.0092],\n",
       "        [ 0.0249, -0.0475, -0.0449, -0.0584,  0.0563,  0.0411, -0.0173],\n",
       "        [ 0.0101, -0.0747, -0.0300, -0.0351,  0.0320,  0.0440,  0.0013],\n",
       "        [ 0.0215, -0.0431, -0.0161, -0.0418,  0.0500,  0.0340, -0.0197],\n",
       "        [ 0.0028, -0.0625, -0.0374, -0.0201,  0.0524,  0.0737, -0.0066],\n",
       "        [ 0.0360, -0.0402, -0.0295, -0.0577,  0.0318,  0.0436, -0.0424],\n",
       "        [-0.0180, -0.0593, -0.0270, -0.0326,  0.0293,  0.0691, -0.0111],\n",
       "        [ 0.0079, -0.0582, -0.0050, -0.0538,  0.0333,  0.0528, -0.0002],\n",
       "        [ 0.0074, -0.0558, -0.0078, -0.0350,  0.0537,  0.0723, -0.0055],\n",
       "        [ 0.0230, -0.0405, -0.0126, -0.0130,  0.0678,  0.0510, -0.0343],\n",
       "        [ 0.0115, -0.0510, -0.0342, -0.0892,  0.0436,  0.0235, -0.0133],\n",
       "        [-0.0084, -0.0264, -0.0058, -0.0339,  0.0598,  0.0669,  0.0097],\n",
       "        [-0.0177, -0.0757,  0.0053, -0.0617,  0.0262,  0.0310,  0.0048]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleGRU().to(device=device)\n",
    "x = torch.randn(64,10,10).to(device=device)\n",
    "y = model(x)\n",
    "x.shape,y.shape\n",
    "\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1822,  0.5373, -0.3509,  0.6588, -0.3443,  0.3314,  0.6150, -0.3198,\n",
       "         -1.2717, -0.5543],\n",
       "        [-0.8845, -1.8585,  0.1797, -0.1284, -0.6218,  0.9519, -0.9108, -0.0652,\n",
       "          0.3551,  0.2951],\n",
       "        [-1.5271,  0.6252,  0.9545, -1.4229,  0.6776, -0.5026, -0.3389, -0.2303,\n",
       "         -1.3512, -1.5314],\n",
       "        [-0.5960,  0.8212,  0.8791, -0.0399,  1.0438,  0.4319, -1.0109, -1.8645,\n",
       "         -0.3983,  1.2355],\n",
       "        [ 0.2788, -0.0725, -0.1116,  0.0456,  0.8689, -1.0621,  0.3665,  0.3647,\n",
       "         -0.2530,  0.7290],\n",
       "        [-1.5337,  1.1668, -1.0408,  0.1020, -0.7847, -1.0911, -0.4360, -1.2183,\n",
       "         -0.8046, -0.2357],\n",
       "        [ 0.6160,  0.9218, -0.6874,  1.7300,  0.7430, -1.4280, -0.1399, -0.0365,\n",
       "          0.7904, -0.8181],\n",
       "        [-1.5431,  0.1405, -0.3673, -0.1808,  0.1712, -0.5992,  0.4093,  1.7636,\n",
       "          0.1674, -0.1030],\n",
       "        [-0.7666,  0.4063, -0.4273,  1.0159, -0.8186,  0.8651,  0.9734, -1.2224,\n",
       "          1.1082, -0.7555],\n",
       "        [-2.2189,  0.7980,  0.1982,  0.2797, -1.3309, -0.2698,  0.2431,  0.4452,\n",
       "          0.8111, -1.9135]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, sequence_length, input_size).to(device)\n",
    "y = torch.randint(0, num_classes, (batch_size,)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch: 0, loss: 1.9496396780014038\n",
      "At epoch: 1, loss: 1.8942210674285889\n",
      "At epoch: 2, loss: 1.8460768461227417\n",
      "At epoch: 3, loss: 1.8008283376693726\n",
      "At epoch: 4, loss: 1.7577062845230103\n"
     ]
    }
   ],
   "source": [
    "current_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = loss_criterion(outputs, y)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"At epoch: {epoch}, loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
